{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mYUPLO_UysSI",
   "metadata": {
    "id": "mYUPLO_UysSI"
   },
   "source": [
    "# Live Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6416c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar modelos\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/lite2/detection/1\")\n",
    "labels = pd.read_csv('labels.csv',sep=';',index_col='ID')\n",
    "labels = labels['OBJECT (2017 REL.)']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#cap = cv2.cvtColor(cap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "width = 1280\n",
    "height = 720\n",
    "trackrange = [(),(),(),()]\n",
    "\n",
    "while(True):\n",
    "    #Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #Resize to respect the input_shape\n",
    "    inp = cv2.resize(frame, (width , height ))\n",
    "\n",
    "    #Convert img to RGB\n",
    "\n",
    "\n",
    "    rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Is optional but i recommend (float convertion and convert img to tensor image)\n",
    "    rgb_tensor = tf.convert_to_tensor(rgb, dtype=tf.uint8)\n",
    "\n",
    "    #Add dims to rgb_tensor\n",
    "    rgb_tensor = tf.expand_dims(rgb_tensor , 0)\n",
    "\n",
    "    boxes, scores, classes, num_detections = detector(rgb_tensor)\n",
    " \n",
    "    pred_labels = classes.numpy().astype('int')[0]\n",
    "    pred_boxes = boxes.numpy()[0].astype('int')\n",
    "    pred_scores = scores.numpy()[0]\n",
    "\n",
    "    # Extract only boxes and labels corresponding to 'person' class\n",
    "    person_boxes = []\n",
    "    person_labels = []\n",
    "    for score, (ymin,xmin,ymax,xmax), label in zip(pred_scores, pred_boxes, pred_labels):\n",
    "        if score < 0.5:\n",
    "            continue\n",
    "        if labels[label] == 'person':\n",
    "            person_boxes.append((ymin, xmin, ymax, xmax))\n",
    "            person_labels.append(labels[label])\n",
    "\n",
    "    # loop throughout the person detections and place a box around it\n",
    "    for box, label in zip(person_boxes, person_labels):\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        img_boxes = cv2.rectangle(inp, (xmin, ymin), (xmax, ymax), (0, 255, 0), 1)      \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img_boxes, label, (xmin, ymax-10), font, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "    #Display the resulting frame\n",
    "    cv2.imshow('black and white', img_boxes)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b30f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar modelos\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/lite2/detection/1\")\n",
    "labels = pd.read_csv('labels.csv', sep=';', index_col='ID')\n",
    "labels = labels['OBJECT (2017 REL.)']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = 720\n",
    "height = 720\n",
    "\n",
    "# Define the ROI mask\n",
    "mask = np.zeros((height, width), dtype=np.uint8)\n",
    "roi_poly = np.array([[(240, 240), (480, 240), (480, 480), (240, 480)]])\n",
    "cv2.fillPoly(mask, roi_poly, 255)\n",
    "\n",
    "img_boxes = None\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Resize to respect the input_shape\n",
    "    inp = cv2.resize(frame, (width, height))\n",
    "\n",
    "    # Convert img to RGB\n",
    "    rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Apply the ROI mask to the input image\n",
    "    masked_rgb = cv2.bitwise_and(rgb, rgb, mask=mask)\n",
    "\n",
    "    # Is optional but i recommend (float convertion and convert img to tensor image)\n",
    "    rgb_tensor = tf.convert_to_tensor(masked_rgb, dtype=tf.uint8)\n",
    "\n",
    "    # Add dims to rgb_tensor\n",
    "    rgb_tensor = tf.expand_dims(rgb_tensor, 0)\n",
    "\n",
    "    boxes, scores, classes, num_detections = detector(rgb_tensor)\n",
    "\n",
    "    pred_labels = classes.numpy().astype('int')[0]\n",
    "    pred_boxes = boxes.numpy()[0].astype('int')\n",
    "    pred_scores = scores.numpy()[0]\n",
    "\n",
    "    # Extract only boxes and labels corresponding to 'person' class within ROI\n",
    "    person_boxes = []\n",
    "    person_labels = []\n",
    "    for score, (ymin, xmin, ymax, xmax), label in zip(pred_scores, pred_boxes, pred_labels):\n",
    "        if score < 0.5:\n",
    "            continue\n",
    "        if labels[label] == 'person':\n",
    "            # Translate the box coordinates to the masked image coordinates\n",
    "            ymin -= 240\n",
    "            ymax -= 240\n",
    "            xmin -= 240\n",
    "            xmax -= 240\n",
    "            if (xmin >= 0) and (ymin >= 0) and (xmax <= 240) and (ymax <= 240):\n",
    "                person_boxes.append((ymin, xmin, ymax, xmax))\n",
    "                person_labels.append(labels[label])\n",
    "\n",
    "    # loop throughout the person detections and place a box around it\n",
    "    img_boxes = frame.copy()  # Create a copy of the frame for drawing boxes\n",
    "    for box, label in zip(person_boxes, person_labels):\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        # Translate the box coordinates to the original frame coordinates\n",
    "        ymin += 240\n",
    "        ymax += 240\n",
    "        xmin += 240\n",
    "        xmax += 240\n",
    "        img_boxes = cv2.rectangle(img_boxes, (xmin, ymin), (xmax, ymax), (0, 255, 0), 1)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img_boxes, label, (xmin, ymax - 10), font, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('black and white', img_boxes)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "       \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_detecion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
